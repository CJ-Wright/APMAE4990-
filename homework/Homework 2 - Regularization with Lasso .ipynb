{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework, you'll be required to load in a dataset which has about 500 features. By using\n",
    "Lasso ($L^1$) regression, we'll find the optimal constraint on the $L^1$ norm which gives us the best\n",
    "$R^2$. Then we'll plot the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Load in hw2data.csv from ../data into a pandas dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Set to be the y variable in the dataframe from a and X to be the remaining features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) As shown in the Booking.com example, using Lasso regression, find the regularization strength\n",
    "which optimizes the $R^2$. \n",
    "\n",
    "**Hint:** Take a range of alpha from `np.logspace(-8,-3,1000)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Plot the training perforamnce versus the testing performance, and observe whree the test performance is\n",
    "maximized. I've written an outline of the code you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.subplot(2, 1, 1)\n",
    "\n",
    "# Fill these in\n",
    "alphas = []\n",
    "train_errors=[]\n",
    "test_errors=[]\n",
    "alpha_optim=0\n",
    "\n",
    "\n",
    "\n",
    "plt.semilogx(alphas, train_errors, label='Train')\n",
    "plt.semilogx(alphas, test_errors, label='Test')\n",
    "plt.vlines(alpha_optim, plt.ylim()[0], np.max(test_errors), color='k',\n",
    "           linewidth=3, label='Optimum on test')\n",
    "plt.legend(loc='lower left')\n",
    "plt.ylim([0, 1.2])\n",
    "plt.xlabel('Regularization parameter')\n",
    "plt.ylabel('Performance')\n",
    "\n",
    "# Show estimated coef_ vs true coef\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(coef, label='True coef')\n",
    "plt.plot(coef_, label='Estimated coef')\n",
    "plt.legend()\n",
    "plt.subplots_adjust(0.09, 0.04, 0.94, 0.94, 0.26, 0.26)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Plot the top coefficients based on this optimal paramter. Why do you think so many are zero? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Compute the $R^2$ with the optimal coefficient found above on 5 folds using cross_val_score and plot the\n",
    "results. Does the model work well on all random subsets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Repeat e) but using cross validation. Use error bars on the features which are the standard deviation of the \n",
    "coefficiens obtained above. For this problem I\"ll walk you through the code. You just need to apply your optimal\n",
    "$\\alpha$ found above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "def run_cv_coeffs(X,y,clf_class,**kwargs):\n",
    "    # Construct a kfolds object\n",
    "    kf = KFold(len(y),n_folds=5,shuffle=True)\n",
    "    y_pred = y.copy()\n",
    "    coeffs=[]\n",
    "    # Iterate through folds\n",
    "    for train_index, test_index in kf:\n",
    "        \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train = y[train_index]\n",
    "        # Initialize a classifier with key word arguments\n",
    "        clf = clf_class(**kwargs)\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred[test_index] = clf.predict(X_test)\n",
    "        coeffs.append(clf.coef_)\n",
    "    return coeffs\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X2 = X.as_matrix().astype(np.float)\n",
    "X2 = scaler.fit_transform(X)\n",
    "\n",
    "coeffs=run_cv_coeffs(X2,np.array(y),Lasso,alpha=alpha_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_coeffs(coeffs):\n",
    "    coeffs_avgd = [(coeffs[0][i] + coeffs[1][i] + coeffs[2][i] + coeffs[3][i] + coeffs[4][i])/5 for i in range(0,len(X.columns))]\n",
    "    coeffs_std = [np.std([coeffs[0][i],coeffs[1][i],coeffs[2][i],coeffs[3][i],coeffs[4][i]]) for i in range(0,len(X.columns))]\n",
    "    return coeffs_avgd, coeffs_std\n",
    "coeffs_avg,coeffs_std=get_coeffs(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16ef6d090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfCoeffs = pd.DataFrame({'type':X.columns.values, 'coef':coeffs_avg, 'std':coeffs_std})\n",
    "dfCoeffs = dfCoeffs[(dfCoeffs['coef']>1) |(dfCoeffs['coef']<-1) ]\n",
    "plt.figure(figsize=(15,15))\n",
    "dfCoeffs_sorted = dfCoeffs.sort(['coef'])[::-1]\n",
    "yerr_vals = dfCoeffs_sorted['std'].values\n",
    "dfCoeffs_sorted.plot(x='type',y='coef',kind='bar',yerr=yerr_vals,figsize=(15,15))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
